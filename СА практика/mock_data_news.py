"""
–ú–æ–¥—É–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∏–º–∏—Ç–∞—Ü–∏–µ–π ML-–º–æ–¥–µ–ª–∏ –¥–ª—è NewsClassify AI
–¢–µ–ø–µ—Ä—å confidence —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π –¥–ª—è –í–°–ï–• —Ç–µ–º!
"""

import random
import re
from datetime import datetime
from collections import Counter


class MockMLClassifier:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–º–∏—Ç–∞—Ü–∏—è ML-–º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ confidence"""

    def __init__(self):
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å –≤–µ—Å–∞–º–∏
        self.topic_keywords = {
            "–ü–æ–ª–∏—Ç–∏–∫–∞": {
                "—Å–∏–ª—å–Ω—ã–µ": ["–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ", "–≤—ã–±–æ—Ä—ã", "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç", "—Å–∞–Ω–∫—Ü–∏–∏", "–∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç", "–¥–µ–ø—É—Ç–∞—Ç"],
                "—Å—Ä–µ–¥–Ω–∏–µ": ["–ø–æ–ª–∏—Ç–∏–∫–∞", "–≤–ª–∞—Å—Ç—å", "–≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ", "—Ä–µ—Ñ–æ—Ä–º–∞", "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è"],
                "—Å–ª–∞–±—ã–µ": ["–ø–æ–ª–∏—Ç–∏–∫", "–∫–∞–º–ø–∞–Ω–∏—è", "–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã", "–¥–∏–ø–ª–æ–º–∞—Ç–∏—è"]
            },
            "–≠–∫–æ–Ω–æ–º–∏–∫–∞": {
                "—Å–∏–ª—å–Ω—ã–µ": ["—ç–∫–æ–Ω–æ–º–∏–∫–∞", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "–∏–Ω—Ñ–ª—è—Ü–∏—è", "—Ä—ã–Ω–æ–∫", "–±–∏—Ä–∂", "–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç"],
                "—Å—Ä–µ–¥–Ω–∏–µ": ["—Ñ–∏–Ω–∞–Ω—Å—ã", "–±–∏–∑–Ω–µ—Å", "–≤–∞–ª—é—Ç–∞", "–±–∞–Ω–∫", "—Ñ–æ–Ω–¥–æ–≤—ã–π"],
                "—Å–ª–∞–±—ã–µ": ["–¥–µ–Ω—å–≥–∏", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "–ø—Ä–∏–±—ã–ª—å", "—É–±—ã—Ç–æ–∫", "–¥–æ—Ö–æ–¥"]
            },
            "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": {
                "—Å–∏–ª—å–Ω—ã–µ": ["–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–Ω–µ–π—Ä–æ—Å–µ—Ç—å", "–∫–≤–∞–Ω—Ç–æ–≤—ã–π", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ", "–∞–ª–≥–æ—Ä–∏—Ç–º"],
                "—Å—Ä–µ–¥–Ω–∏–µ": ["—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–≥–∞–¥–∂–µ—Ç", "—Å—Ç–∞—Ä—Ç–∞–ø", "–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏", "IT", "—Ü–∏—Ñ—Ä–æ–≤–æ–π"],
                "—Å–ª–∞–±—ã–µ": ["–∫–æ–º–ø—å—é—Ç–µ—Ä", "—Å–º–∞—Ä—Ç—Ñ–æ–Ω", "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç", "—Å–æ—Ñ—Ç"]
            },
            "–ù–∞—É–∫–∞": {
                "—Å–∏–ª—å–Ω—ã–µ": ["–Ω–∞—É—á–Ω–æ–µ –æ—Ç–∫—Ä—ã—Ç–∏–µ", "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç", "–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è", "–≥–∏–ø–æ—Ç–µ–∑–∞"],
                "—Å—Ä–µ–¥–Ω–∏–µ": ["–Ω–∞—É–∫–∞", "—É—á–µ–Ω—ã–µ", "–ø—É–±–ª–∏–∫–∞—Ü–∏—è", "—Ç–µ–æ—Ä–∏—è", "–æ—Ç–∫—Ä—ã—Ç–∏–µ"],
                "—Å–ª–∞–±—ã–µ": ["–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å", "–Ω–∞—É—á–Ω—ã–π", "–∏–∑—É—á–µ–Ω–∏–µ", "–∞–Ω–∞–ª–∏–∑", "–º–µ—Ç–æ–¥"]
            },
            "–ú–µ–¥–∏—Ü–∏–Ω–∞": {
                "—Å–∏–ª—å–Ω—ã–µ": ["–º–µ–¥–∏—Ü–∏–Ω–∞", "–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", "–≤–∞–∫—Ü–∏–Ω–∞", "–ª–µ–∫–∞—Ä—Å—Ç–≤–æ", "—Ç–µ—Ä–∞–ø–∏—è", "–æ–Ω–∫–æ–ª–æ–≥–∏—è"],
                "—Å—Ä–µ–¥–Ω–∏–µ": ["–∑–¥–æ—Ä–æ–≤—å–µ", "–≤—Ä–∞—á", "–±–æ–ª—å–Ω–∏—Ü–∞", "–ø–∞—Ü–∏–µ–Ω—Ç", "–ª–µ—á–µ–Ω–∏–µ", "–ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞"],
                "—Å–ª–∞–±—ã–µ": ["–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π", "–∫–ª–∏–Ω–∏–∫–∞", "–∑–¥–æ—Ä–æ–≤—å–µ", "–¥–∏–∞–≥–Ω–æ–∑", "—Å–∏–º–ø—Ç–æ–º"]
            },
            "–°–ø–æ—Ä—Ç": {
                "—Å–∏–ª—å–Ω—ã–µ": ["—á–µ–º–ø–∏–æ–Ω–∞—Ç", "–æ–ª–∏–º–ø–∏–∞–¥–∞", "—Ñ—É—Ç–±–æ–ª", "–º–∞—Ç—á", "–ø–æ–±–µ–¥–∞", "—Ä–µ–∫–æ—Ä–¥"],
                "—Å—Ä–µ–¥–Ω–∏–µ": ["—Å–ø–æ—Ä—Ç", "–∏–≥—Ä–æ–∫", "—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ", "—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞", "–∫–æ–º–∞–Ω–¥–∞"],
                "—Å–ª–∞–±—ã–µ": ["—Å–ø–æ—Ä—Ç—Å–º–µ–Ω", "–∏–≥—Ä–∞", "—Ç—É—Ä–Ω–∏—Ä", "—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è", "–ª–∏–≥–∞"]
            },
            "–ö—É–ª—å—Ç—É—Ä–∞": {
                "—Å–∏–ª—å–Ω—ã–µ": ["–∫—É–ª—å—Ç—É—Ä–∞", "–∏—Å–∫—É—Å—Å—Ç–≤–æ", "–º—É–∑–µ–π", "—Ç–µ–∞—Ç—Ä", "–≤—ã—Å—Ç–∞–≤–∫–∞", "–∫–æ–Ω—Ü–µ—Ä—Ç"],
                "—Å—Ä–µ–¥–Ω–∏–µ": ["—Ñ–∏–ª—å–º", "–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞", "–º—É–∑—ã–∫–∞", "–∞—Ä—Ç–∏—Å—Ç", "—Ö—É–¥–æ–∂–Ω–∏–∫"],
                "—Å–ª–∞–±—ã–µ": ["–∫—É–ª—å—Ç—É—Ä–Ω—ã–π", "—Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ", "–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ", "–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å", "–∞–≤—Ç–æ—Ä"]
            },
            "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ": {
                "—Å–∏–ª—å–Ω—ã–µ": ["–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ", "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç", "—Å—Ç—É–¥–µ–Ω—Ç", "—ç–∫–∑–∞–º–µ–Ω", "—É—á–µ–±–Ω–∏–∫", "–∫—É—Ä—Å"],
                "—Å—Ä–µ–¥–Ω–∏–µ": ["—à–∫–æ–ª–∞", "–æ–±—É—á–µ–Ω–∏–µ", "–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å", "–ø—Ä–æ–≥—Ä–∞–º–º–∞", "–¥–∏–ø–ª–æ–º"],
                "—Å–ª–∞–±—ã–µ": ["—É—á–µ–±–Ω—ã–π", "–∑–∞–Ω—è—Ç–∏–µ", "—É—Ä–æ–∫", "–ª–µ–∫—Ü–∏—è", "—Å–µ–º–∏–Ω–∞—Ä"]
            }
        }

        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        self.keyword_weights = {
            "—Å–∏–ª—å–Ω—ã–µ": 5.0,
            "—Å—Ä–µ–¥–Ω–∏–µ": 3.0,
            "—Å–ª–∞–±—ã–µ": 1.0
        }

        # –ë–∞–∑–æ–≤—ã–µ –≤–µ—Å–∞ —Ç–µ–º
        self.topic_weights = {
            "–ü–æ–ª–∏—Ç–∏–∫–∞": 1.0,
            "–≠–∫–æ–Ω–æ–º–∏–∫–∞": 1.0,
            "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": 1.0,
            "–ù–∞—É–∫–∞": 1.0,
            "–ú–µ–¥–∏—Ü–∏–Ω–∞": 1.0,
            "–°–ø–æ—Ä—Ç": 1.0,
            "–ö—É–ª—å—Ç—É—Ä–∞": 1.0,
            "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ": 1.0
        }

        self.training_history = []
        print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def predict_topic(self, title, content):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–µ–º—ã —Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ confidence"""
        combined_text = (title + " " + content).lower()

        # –î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã —Å—á–∏—Ç–∞–µ–º score
        topic_scores = {}
        for topic, keyword_groups in self.topic_keywords.items():
            score = 0
            base_weight = self.topic_weights[topic]

            for keyword_type, keywords in keyword_groups.items():
                weight = self.keyword_weights[keyword_type]
                for keyword in keywords:
                    pattern = r'\b' + re.escape(keyword) + r'\b'
                    matches = re.findall(pattern, combined_text)
                    if matches:
                        score += weight * len(matches)
                        if keyword in title.lower():
                            score += weight * 2

            score *= base_weight
            score *= random.uniform(0.8, 1.2)  # –í–∞—Ä–∏–∞—Ü–∏—è
            topic_scores[topic] = score

        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é —Ç–µ–º—É
        best_topic = max(topic_scores, key=topic_scores.get)
        best_score = topic_scores[best_topic]

        # –í—ã—á–∏—Å–ª—è–µ–º confidence
        confidence = self._calculate_confidence(best_score, topic_scores, combined_text, title, best_topic)

        print(f"üéØ ML: '{title[:30]}...' ‚Üí {best_topic} ({confidence:.0%})")
        return best_topic, confidence

    def _calculate_confidence(self, best_score, all_scores, text, title, best_topic):
        """–†–∞—Å—á–µ—Ç confidence —Å —É—á–µ—Ç–æ–º —Ç–µ–º—ã"""
        # –û—Ç—Ä—ã–≤ –æ—Ç –≤—Ç–æ—Ä–æ–π –ª—É—á—à–µ–π —Ç–µ–º—ã
        sorted_scores = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)

        if len(sorted_scores) > 1:
            best_score = sorted_scores[0][1]
            second_best = sorted_scores[1][1]
            lead_ratio = (best_score - second_best) / best_score if best_score > 0 else 0
        else:
            lead_ratio = 0

        # –§–∞–∫—Ç–æ—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–µ–º (–∏–º–∏—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å)
        topic_difficulty = {
            "–ü–æ–ª–∏—Ç–∏–∫–∞": 0.7,  # –ß–∞—Å—Ç–æ –º–µ–∂–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω–∞—è
            "–≠–∫–æ–Ω–æ–º–∏–∫–∞": 0.6,  # –ú–Ω–æ–≥–æ —Ü–∏—Ñ—Ä –∏ —Ç–µ—Ä–º–∏–Ω–æ–≤
            "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": 0.8,  # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
            "–ù–∞—É–∫–∞": 0.9,  # –°–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
            "–ú–µ–¥–∏—Ü–∏–Ω–∞": 0.85,  # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è
            "–°–ø–æ—Ä—Ç": 0.5,  # –û–±—ã—á–Ω–æ –ø—Ä–æ—Å—Ç–∞—è
            "–ö—É–ª—å—Ç—É—Ä–∞": 0.6,  # –°—Ä–µ–¥–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ": 0.7  # –ú–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–∂–Ω–æ–π
        }

        # –ë–∞–∑–æ–≤—ã–π confidence –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—Ä—ã–≤–∞
        if lead_ratio > 0.5:
            base_confidence = 0.93
        elif lead_ratio > 0.3:
            base_confidence = 0.85
        elif lead_ratio > 0.1:
            base_confidence = 0.75
        else:
            base_confidence = 0.65

        # –£—á–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Ç–µ–º—ã
        difficulty = topic_difficulty.get(best_topic, 0.7)
        difficulty_factor = 1.0 - (difficulty * 0.15)

        # –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
        word_count = len(text.split())
        if word_count < 50:
            length_factor = 1.1
        elif word_count < 150:
            length_factor = 1.0
        else:
            length_factor = 0.9

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
        title_has_keywords = any(
            keyword in title.lower()
            for keyword_group in self.topic_keywords[best_topic].values()
            for keyword in keyword_group
        )
        title_factor = 1.15 if title_has_keywords else 1.0

        # –ò—Ç–æ–≥–æ–≤—ã–π confidence
        final_confidence = base_confidence * difficulty_factor * length_factor * title_factor
        final_confidence *= random.uniform(0.97, 1.03)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏ –æ–∫—Ä—É–≥–ª—è–µ–º
        final_confidence = max(0.6, min(0.98, final_confidence))
        return round(final_confidence, 2)

    def learn_from_correction(self, article_id, old_topic, new_topic):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏"""
        self.training_history.append({
            "article_id": article_id,
            "old_topic": old_topic,
            "new_topic": new_topic,
            "timestamp": datetime.now()
        })

        if new_topic in self.topic_weights:
            self.topic_weights[new_topic] = min(2.0, self.topic_weights[new_topic] + 0.07)

        if old_topic in self.topic_weights:
            self.topic_weights[old_topic] = max(0.5, self.topic_weights[old_topic] - 0.04)

        print(f"üìö ML –æ–±—É—á–µ–Ω–∏–µ: {old_topic} ‚Üí {new_topic}")


class MockNewsData:
    def __init__(self):
        self.ml_classifier = MockMLClassifier()
        self.available_topics = list(self.ml_classifier.topic_keywords.keys())
        self.articles = self._generate_diverse_articles()
        self.user_filters = []
        self.classification_stats = self._calculate_stats()
        self.correction_history = []

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        self._add_test_filters()

        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(self.articles)} —Å—Ç–∞—Ç–µ–π")
        print(f"üìä –°—Ç–∞—Ç—å–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –ø–æ confidence:")
        self._show_confidence_distribution()

    def _add_test_filters(self):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
        print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤...")

        # –§–∏–ª—å—Ç—Ä 1: –ò–ò –≤ –º–µ–¥–∏—Ü–∏–Ω–µ
        self.create_filter(
            name="–ò–ò –≤ –º–µ–¥–∏—Ü–∏–Ω–µ",
            topic="–ú–µ–¥–∏—Ü–∏–Ω–∞",
            keywords=["–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", "–Ω–µ–π—Ä–æ—Å–µ—Ç—å"],
            logic="OR"
        )

        # –§–∏–ª—å—Ç—Ä 2: –ö—Ä–∏–ø—Ç–æ-–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏
        self.create_filter(
            name="–ö—Ä–∏–ø—Ç–æ-–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏",
            topic="–≠–∫–æ–Ω–æ–º–∏–∫–∞",
            keywords=["–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç", "–±–∏—Ç–∫–æ–∏–Ω", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏"],
            logic="OR"
        )

        # –§–∏–ª—å—Ç—Ä 3: –í—ã—Å–æ–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
        self.create_filter(
            name="–í—ã—Å–æ–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
            topic="–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
            keywords=["–∫–≤–∞–Ω—Ç–æ–≤—ã–π", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–Ω–µ–π—Ä–æ—Å–µ—Ç—å"],
            logic="OR"
        )

        # –§–∏–ª—å—Ç—Ä 4: –°—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä (–ò –ª–æ–≥–∏–∫–∞)
        self.create_filter(
            name="–°–ª–æ–∂–Ω—ã–µ –º–µ–¥ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
            topic="–ú–µ–¥–∏—Ü–∏–Ω–∞",
            keywords=["–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "—É—á–µ–Ω—ã–µ", "–≤–∞–∫—Ü–∏–Ω"],
            logic="AND"
        )

        # –§–∏–ª—å—Ç—Ä 5: –§–∏–ª—å—Ç—Ä –±–µ–∑ —Ç–µ–º—ã
        self.create_filter(
            name="–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –∏ —Å—Ç–∞—Ä—Ç–∞–ø—ã",
            topic=None,
            keywords=["–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "—Å—Ç–∞—Ä—Ç–∞–ø", "—Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ"],
            logic="OR"
        )

        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(self.user_filters)} —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤")

    def _generate_diverse_articles(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç—å–∏ —Å –†–ê–ó–ù–û–û–ë–†–ê–ó–ù–´–ú–ò confidence –¥–ª—è –≤—Å–µ—Ö —Ç–µ–º"""
        article_templates = [
            # –í–´–°–û–ö–ò–ô CONFIDENCE (>90%) - —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã
            {"title": "–ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –ø–æ–¥–ø–∏—Å–∞–ª –Ω–æ–≤—ã–π –∑–∞–∫–æ–Ω –æ –≤—ã–±–æ—Ä–∞—Ö",
             "content": "–î–æ–∫—É–º–µ–Ω—Ç –≤–Ω–æ—Å–∏—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω–æ–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ.",
             "source": "–í–µ–¥–æ–º–æ—Å—Ç–∏", "date": "10.01.2024", "target_confidence": "high"},

            {"title": "–§–æ–Ω–¥–æ–≤—ã–π —Ä—ã–Ω–æ–∫ –ø–æ–∫–∞–∑–∞–ª —Ä–µ–∫–æ—Ä–¥–Ω—ã–π —Ä–æ—Å—Ç",
             "content": "–û—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 3-5% –∑–∞ —Ç–æ—Ä–≥–æ–≤—É—é —Å–µ—Å—Å–∏—é.",
             "source": "–†–ë–ö", "date": "15.01.2024", "target_confidence": "high"},

            {"title": "–ù–æ–≤—ã–π –∫–≤–∞–Ω—Ç–æ–≤—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä —É—Å—Ç–∞–Ω–æ–≤–∏–ª —Ä–µ–∫–æ—Ä–¥",
             "content": "–£—á–µ–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å 512 –∫—É–±–∏—Ç–∞–º–∏.",
             "source": "–•–∞–±—Ä", "date": "14.01.2024", "target_confidence": "high"},

            {"title": "–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞ –≤–∞–∫—Ü–∏–Ω–∞ –æ—Ç —Å–µ–∑–æ–Ω–Ω–æ–≥–æ –≥—Ä–∏–ø–ø–∞",
             "content": "–ú–∏–Ω–∑–¥—Ä–∞–≤ –æ–¥–æ–±—Ä–∏–ª –ø—Ä–µ–ø–∞—Ä–∞—Ç —Å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é 95%.",
             "source": "–ú–µ–¥–ø–æ—Ä—Ç–∞–ª", "date": "13.01.2024", "target_confidence": "high"},

            {"title": "–§–∏–Ω–∞–ª—å–Ω—ã–π –º–∞—Ç—á —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ –º–∏—Ä–∞ –ø–æ —Ñ—É—Ç–±–æ–ª—É",
             "content": "–°–±–æ—Ä–Ω–∞—è –ê—Ä–≥–µ–Ω—Ç–∏–Ω—ã –æ–±—ã–≥—Ä–∞–ª–∞ –ë—Ä–∞–∑–∏–ª–∏—é —Å–æ —Å—á–µ—Ç–æ–º 3:2.",
             "source": "–°–ø–æ—Ä—Ç-–≠–∫—Å–ø—Ä–µ—Å—Å", "date": "07.01.2024", "target_confidence": "high"},

            # –°–†–ï–î–ù–ò–ô CONFIDENCE (80-90%) - —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã
            {"title": "–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Ä–µ—Ñ–æ—Ä–º—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ",
             "content": "–≠–∫—Å–ø–µ—Ä—Ç—ã –æ–±—Å—É–∂–¥–∞—é—Ç –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –Ω–∞–ª–æ–≥–æ–≤–æ–º –∫–æ–¥–µ–∫—Å–µ.",
             "source": "–í–µ–¥–æ–º–æ—Å—Ç–∏", "date": "09.01.2024", "target_confidence": "medium"},

            {"title": "–ö–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –º–∏—Ä–µ",
             "content": "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã –æ–±—Å—É–∂–¥–∞—é—Ç –º–µ—Ç–æ–¥—ã –∑–∞—â–∏—Ç—ã –æ—Ç –∫–∏–±–µ—Ä–∞—Ç–∞–∫.",
             "source": "SecurityLab", "date": "08.01.2024", "target_confidence": "medium"},

            {"title": "–ö–ª–∏–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ –∏—Ö –∑–Ω–∞—á–µ–Ω–∏–µ",
             "content": "–£—á–µ–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –æ –≥–ª–æ–±–∞–ª—å–Ω–æ–º –ø–æ—Ç–µ–ø–ª–µ–Ω–∏–∏.",
             "source": "Nature", "date": "06.01.2024", "target_confidence": "medium"},

            {"title": "–î–∏—Å—Ç–∞–Ω—Ü–∏–æ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏",
             "content": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–Ω–ª–∞–π–Ω-–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.",
             "source": "Education Week", "date": "05.01.2024", "target_confidence": "medium"},

            {"title": "–¶–∏—Ñ—Ä–æ–≤–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–æ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º—É–∑–µ—è—Ö",
             "content": "–ú—É–∑–µ–∏ –Ω–∞—á–∏–Ω–∞—é—Ç –ø—Ä–∏–æ–±—Ä–µ—Ç–∞—Ç—å —Ü–∏—Ñ—Ä–æ–≤—ã–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è.",
             "source": "ArtNews", "date": "04.01.2024", "target_confidence": "medium"},

            # –ù–ò–ó–ö–ò–ô CONFIDENCE (60-80%) - —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã
            {"title": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ",
             "content": "–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –ø–æ–º–æ–≥–∞—é—Ç –≤—Ä–∞—á–∞–º –≤ –∞–Ω–∞–ª–∏–∑–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å–Ω–∏–º–∫–æ–≤.",
             "source": "N+1", "date": "11.01.2024", "target_confidence": "low"},

            {"title": "–¶–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã",
             "content": "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –º–µ–Ω—è—é—Ç –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é –≤ —à–∫–æ–ª–∞—Ö –∏ –≤—É–∑–∞—Ö.",
             "source": "–ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç", "date": "12.01.2024", "target_confidence": "low"},

            {"title": "–ù–∞—É—á–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ –±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π",
             "content": "–£—á–µ–Ω—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤—ã—Ö —Å–æ—Ä—Ç–æ–≤ —Ä–∞—Å—Ç–µ–Ω–∏–π.",
             "source": "AgroNews", "date": "03.01.2024", "target_confidence": "low"},

            {"title": "–§–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å—Ç–∞—Ä—Ç–∞–ø–æ–≤",
             "content": "–ò–Ω–≤–µ—Å—Ç–æ—Ä—ã –≤–∫–ª–∞–¥—ã–≤–∞—é—Ç —Å—Ä–µ–¥—Å—Ç–≤–∞ –≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã.",
             "source": "Bloomberg", "date": "02.01.2024", "target_confidence": "low"},

            {"title": "–°–ø–æ—Ä—Ç–∏–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö",
             "content": "–ö–æ–º–∞–Ω–¥—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç big data –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–π.",
             "source": "SportsTech", "date": "01.01.2024", "target_confidence": "low"},

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
            {"title": "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –¥–ª—è –Ω–∞—É–∫–∏",
             "content": "IT-–∫–æ–º–ø–∞–Ω–∏–∏ —Å–æ–∑–¥–∞—é—Ç —Å–æ—Ñ—Ç –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–¥–∞—á.",
             "source": "–•–∞–±—Ä", "date": "31.12.2023", "target_confidence": "medium"},

            {"title": "–ú—É–∑–µ–π–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å",
             "content": "–≠–∫—Å–ø–æ–∑–∏—Ü–∏–∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Å –ø–æ–º–æ—â—å—é VR.",
             "source": "–ö—É–ª—å—Ç—É—Ä–∞.—Ä—Ñ", "date": "30.12.2023", "target_confidence": "medium"},

            {"title": "–≠–∫–æ–Ω–æ–º–∏–∫–∞ –∏ —ç–∫–æ–ª–æ–≥–∏—è: –ø–æ–∏—Å–∫ –±–∞–ª–∞–Ω—Å–∞",
             "content": "–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è –≤–Ω–µ–¥—Ä—è—é—Ç –∑–µ–ª–µ–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏.",
             "source": "–≠–∫–æ–ù–æ–≤–æ—Å—Ç–∏", "date": "29.12.2023", "target_confidence": "low"},

            {"title": "–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ —ç—Ç–∏–∫–∞",
             "content": "–£—á–µ–Ω—ã–µ –æ–±—Å—É–∂–¥–∞—é—Ç –≤–æ–ø—Ä–æ—Å—ã –±–∏–æ—ç—Ç–∏–∫–∏ –≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö.",
             "source": "–ú–µ–¥–Ω–æ–≤–æ—Å—Ç–∏", "date": "28.12.2023", "target_confidence": "low"},

            {"title": "–ü–æ–ª–∏—Ç–∏–∫–∞ –∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è",
             "content": "–°—Ç—Ä–∞–Ω—ã –æ–±—Å—É–∂–¥–∞—é—Ç –Ω–æ–≤—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞.",
             "source": "Euronews", "date": "27.12.2023", "target_confidence": "medium"},

            # –°—Ç–∞—Ç—å–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
            {"title": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ —Ä–∞–∫–∞",
             "content": "–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –ø–æ–∫–∞–∑–∞–ª–∏ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –æ–ø—É—Ö–æ–ª–µ–π –Ω–∞ —Ä–∞–Ω–Ω–∏—Ö —Å—Ç–∞–¥–∏—è—Ö.",
             "source": "–ú–µ–¥–Ω–æ–≤–æ—Å—Ç–∏", "date": "16.01.2024", "target_confidence": "high"},

            {"title": "–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã –¥–æ—Å—Ç–∏–≥–ª–∏ —Ä–µ–∫–æ—Ä–¥–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è",
             "content": "–ë–∏—Ç–∫–æ–∏–Ω –ø—Ä–∏–≤–ª–µ–∫ –±–æ–ª–µ–µ 10 –º–ª—Ä–¥ –¥–æ–ª–ª–∞—Ä–æ–≤ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤ —ç—Ç–æ–º –≥–æ–¥—É.",
             "source": "–†–ë–ö", "date": "17.01.2024", "target_confidence": "high"},

            {"title": "–ö–≤–∞–Ω—Ç–æ–≤—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π",
             "content": "–£—á–µ–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∫–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤—ã—Ö –ª–µ–∫–∞—Ä—Å—Ç–≤.",
             "source": "–•–∞–±—Ä", "date": "18.01.2024", "target_confidence": "medium"},
        ]

        articles = []

        for i, template in enumerate(article_templates, 1):
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç ML
            predicted_topic, confidence = self.ml_classifier.predict_topic(
                template["title"], template["content"]
            )

            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º confidence –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ü–µ–ª–µ–≤–æ–π –≥—Ä—É–ø–ø–µ
            if template["target_confidence"] == "high":
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º confidence –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö
                confidence = min(0.98, confidence * 1.1)
            elif template["target_confidence"] == "low":
                # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è –Ω–∏–∑–∫–∏—Ö
                confidence = max(0.6, confidence * 0.85)
            # –î–ª—è medium –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (80-90%)

            confidence = round(confidence, 2)

            article = {
                "id": i,
                "title": template["title"],
                "content": template["content"],
                "source": template["source"],
                "date": template["date"],
                "predicted_topic": predicted_topic,
                "confidence": confidence,
                "true_topic": None
            }

            articles.append(article)

        return articles

    def _show_confidence_distribution(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ confidence –ø–æ —Ç–µ–º–∞–º"""
        print("\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï CONFIDENCE –ü–û –¢–ï–ú–ê–ú:")
        print("-" * 50)

        for topic in self.available_topics:
            topic_articles = [a for a in self.articles if a["predicted_topic"] == topic]
            if topic_articles:
                confidences = [a["confidence"] for a in topic_articles]
                avg_conf = sum(confidences) / len(confidences)

                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ
                high = len([c for c in confidences if c > 0.9])
                medium = len([c for c in confidences if 0.8 <= c <= 0.9])
                low = len([c for c in confidences if c < 0.8])

                print(f"\n{topic}:")
                print(f"  üìà –°—Ä–µ–¥–Ω–∏–π confidence: {avg_conf:.1%}")
                print(f"  üü¢ –í—ã—Å–æ–∫–∞—è: {high} —Å—Ç–∞—Ç–µ–π")
                print(f"  üü† –°—Ä–µ–¥–Ω—è—è: {medium} —Å—Ç–∞—Ç–µ–π")
                print(f"  üî¥ –ù–∏–∑–∫–∞—è: {low} —Å—Ç–∞—Ç–µ–π")

    def _calculate_stats(self):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        total = len(self.articles)

        high = len([a for a in self.articles if a["confidence"] > 0.9])
        medium = len([a for a in self.articles if 0.8 <= a["confidence"] <= 0.9])
        low = len([a for a in self.articles if a["confidence"] < 0.8])

        return {
            "precision": 0.87,
            "recall": 0.82,
            "f1_score": 0.85,
            "total_articles": total,
            "corrected_count": 0,
            "high_confidence": high,
            "medium_confidence": medium,
            "low_confidence": low,
            "avg_confidence": sum(a["confidence"] for a in self.articles) / total if total > 0 else 0
        }

    def get_articles_by_filter(self, filter_topic=None):
        if not filter_topic or filter_topic == "–í—Å–µ —Ç–µ–º—ã":
            return self.articles

        return [article for article in self.articles
                if article["predicted_topic"] == filter_topic]

    def get_articles_by_keywords(self, keywords, logic="OR", topic=None):
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç–∞—Ç—å–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
        if not keywords:
            return []

        filtered_articles = []

        for article in self.articles:
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ —Ç–µ–º–∞, —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—ë
            if topic and article["predicted_topic"] != topic:
                continue

            combined_text = (article["title"] + " " + article["content"]).lower()

            if logic == "OR":
                # –°—Ç–∞—Ç—å—è –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –•–û–¢–Ø –ë–´ –û–î–ù–û –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                for keyword in keywords:
                    if keyword.lower() in combined_text:
                        filtered_articles.append(article)
                        break
            elif logic == "AND":
                # –°—Ç–∞—Ç—å—è –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –í–°–ï –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                all_present = True
                for keyword in keywords:
                    if keyword.lower() not in combined_text:
                        all_present = False
                        break
                if all_present:
                    filtered_articles.append(article)

        return filtered_articles

    def correct_article_topic(self, article_id, correct_topic):
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —Ç–µ–º—É —Å—Ç–∞—Ç—å–∏"""
        for article in self.articles:
            if article["id"] == article_id:
                old_topic = article["predicted_topic"]
                old_confidence = article["confidence"]

                article["predicted_topic"] = correct_topic
                article["confidence"] = 1.0
                article["true_topic"] = correct_topic

                self.ml_classifier.learn_from_correction(article_id, old_topic, correct_topic)

                self.correction_history.append({
                    "article_id": article_id,
                    "old_topic": old_topic,
                    "new_topic": correct_topic,
                    "old_confidence": old_confidence,
                    "new_confidence": 1.0,
                    "date": article["date"],
                    "title": article["title"][:30] + "..."
                })

                self.classification_stats['corrected_count'] += 1

                if self.classification_stats['corrected_count'] % 5 == 0:
                    self.classification_stats['precision'] = min(
                        0.98, self.classification_stats['precision'] + 0.01
                    )

                print(f"‚úÖ –°—Ç–∞—Ç—å—è {article_id} –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞: {old_topic} ‚Üí {correct_topic}")
                return True

        return False

    def create_filter(self, name, topic=None, keywords=None, logic="OR"):
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏"""
        new_filter = {
            "id": len(self.user_filters) + 1,
            "name": name,
            "topic": topic,
            "keywords": keywords or [],
            "logic": logic,
            "active": True,
            "created": "2024-01-15"
        }
        self.user_filters.append(new_filter)

        # –¢–µ—Å—Ç–æ–≤—ã–π –≤—ã–≤–æ–¥ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if keywords:
            print(f"üîç –°–æ–∑–¥–∞–Ω —Ñ–∏–ª—å—Ç—Ä —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏: {keywords}")
            # –ü—Ä–æ–≤–µ—Ä–∏–º —Å—Ä–∞–∑—É, —Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ —ç—Ç–æ—Ç —Ñ–∏–ª—å—Ç—Ä
            test_articles = self.get_articles_by_keywords(keywords, logic, topic)
            print(f"üîç –¢–µ—Å—Ç: –Ω–∞–π–¥–µ–Ω–æ {len(test_articles)} —Å—Ç–∞—Ç–µ–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ '{name}'")

        return new_filter

    def get_active_filters(self):
        return [f for f in self.user_filters if f["active"]]


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
mock_data = MockNewsData()